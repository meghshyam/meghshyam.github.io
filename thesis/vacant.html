<!DOCTYPE html>
<html>
<head>

<title>Explorations Through Quadcopters</title>
<meta http-equiv="content-type" content="text/html;charset=utf-8" />
<meta name="description" content="FTM" />

<link rel="stylesheet" href="touching.css" type="text/css" />
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js">
</script>
<script>
$(document).ready(function () {
  $(".scroll-to-top").hide();
  //Check to see if the window is top if not then display button
  $(window).scroll(function () {
  if ($(this).scrollTop() > 200) {
    $(".scroll-to-top").fadeIn();
  } else {
    $(".scroll-to-top").fadeOut();
  }
});
 
//Click event to scroll to top
$(".scroll-to-top").click(function () {
  $("html, body").animate({ scrollTop: 0 }, 800);
  return false;
  });
});
</script>
</head>
<body>

<div class="scroll-to-top">
<a href=”#”>Scroll<br>to Top</a>
</div>

<div id="container">
<div id="banner">
<div id="bannertitle">Explorations Through Quadcopters</div>
</div>

<div id="outer">
<div id="inner">
<div id="left">
<div class="verticalmenu">
  <ul>
    <li><a href="intro.html"> Abstract </a></li>
    <li><a href="summary.html"> Thesis in Nutshell  </a>
<ul class="submenu">
<li><a href="vacant.html">Mosaicing Scenes With Vacant Spaces</a></li>
<li><a href="multiplanar.html">Imaging Multiplanar Scenes</a></li>
<li><a href="fiducial.html">Detecting Fiducials Under Blur</a></li>
</ul>
</li>
    <li><a href="results.html">Sample Results</a></li>
  </ul>
</div> 

</div>
<div id="content">
<div id="vacant">
  <h2>Mosaicing Scenes With Vacant Spaces </h2>
</div>
One of the major contribution of this piece of the thesis is a method to create a mosaic of a scene containing vacant spaces using fusion
of a standard stitching algorithm with positional data captured from a quadcotper.

<h3>Challenges</h3>
<ul>

<li> The standard mosaicing methods use feature matching algorithms for
  estimating the <a href="https://en.wikipedia.org/wiki/Homography_%28computer_vision%29">homography</a> between two images.</li>

<li> Feature matching algorithms require detection of sufficient <a href = "https://en.wikipedia.org/wiki/Speeded_up_robust_features">features</a>. in both images for mosaicing.</li>

<figure>
<center>
<img width=600 src=images/vacantSpacesChallenge.png>
<figcaption style="padding:10px;">Figure 1: Problems in mosaicing due to <a href=intro.html#vacantspaces>vacant spaces</a>. </figcaption>
</center>
</figure>

<li> Scenes containing large regions with vacant spaces result in very few (or almost zero) <a href = "https://en.wikipedia.org/wiki/Speeded_up_robust_features">features</a>.</li>

<li> The feature matching algorithms get confused when parts of the scene are repeated.</li>

<li> Popular mosaicing softwares such as Adobe Photoshop are unable to handle vacant spaces and repetitive patterns.</li>
</ul>

<figure>
<center>
<img width=600 src=images/vacantSpacesExample.png>
<figcaption style="padding:10px;">Figure 2: We could not create a single mosaic of a scene containing vacant spaces using state of the art mosaicing softwares such as Adobe Photoshop.</figcaption>
</center>
</figure>

<h3>Contributions</h3>
<ul>

<li> We use the <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit">IMU</a> data to select representative images from the video and arrange them into rectangular grid according to the 'spatial' neighborhood. 
<ul>
<li> It brings down the number of images to be stitched to a manageable number. </li>
<li>It also  disambiguates situations when multiple images that are spatially distant, have similar, repeated features.</li></ul>
</li>
<li> Whenever there are no <a href = "https://en.wikipedia.org/wiki/Speeded_up_robust_features">features</a> in the overlapped region of two images, we use the IMU data to find the relative position of one mini-panorama with respect to another.</li>

</ul>

<h3> Overview</h3>
<figure>
<center>
<img width=600 src=images/vacantSpacesWorkflow.png>
<figcaption style="padding:10px;">Figure 3: Overview of mosaicing scenes with vacant spaces. </figcaption>
</center>
</figure>

Input imagery is systematically acquired (top left) by a quadcopter.  In the next
    step, interesting images are found by clustering the video into
    regions based on positional data.  A graph is constructed using
    proximal images. For each connected component in a graph, standard
    stitching techniques are used to create mini-panoramas which are
    then joined together into a super panorama 
    again using IMU data.


<br>
</div><!-- end content -->
</div><!-- end inner --> 
</div><!-- end outer -->
<div id="footer"></div>
</div><!-- end container -->
</body>
</html>
